{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df0c083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np # Para np.nan\n",
    "import os # Importar el módulo os para manejar rutas de archivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c46eb397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_connection import get_connection\n",
    "from db_connection import get_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e5941",
   "metadata": {},
   "source": [
    "Tabla accounting_account_balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1385ef95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_account_balances':\n",
      "  - id (bigint unsigned)\n",
      "  - code (double(16,15))\n",
      "  - accounting_id (bigint unsigned)\n",
      "  - name (varchar(255))\n",
      "  - initial_balance (double(18,6))\n",
      "  - final_balance (double(18,6))\n",
      "  - debit_movement (double(18,6))\n",
      "  - credit_movement (double(18,6))\n",
      "  - third_party_type_id (varchar(50))\n",
      "  - third_party_id (bigint unsigned)\n",
      "  - currency_id (varchar(255))\n",
      "  - year (int)\n",
      "  - month (int)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection() # Obtener una nueva conexión o reutilizar si get_connection maneja eso\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_account_balances;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_account_balances':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f007c",
   "metadata": {},
   "source": [
    "Eliminación de columna que no aportan información relevante (created_at, update_at)\n",
    "También se eliminan las constantes tales como (currency_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "440af08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'accounting_account_balances'...\n",
      "Tabla 'accounting_account_balances' cargada exitosamente. Filas: 4499, Columnas: 15\n",
      "\n",
      "Eliminando columnas 'created_at', 'updated_at', y 'currency_id'...\n",
      "Columnas ['created_at', 'updated_at', 'currency_id'] eliminadas exitosamente.\n",
      "\n",
      "Columnas restantes en el DataFrame 'accounting_account_balances':\n",
      "['id', 'code', 'accounting_id', 'name', 'initial_balance', 'final_balance', 'debit_movement', 'credit_movement', 'third_party_type_id', 'third_party_id', 'year', 'month']\n",
      "\n",
      "Primeras 5 filas del DataFrame 'accounting_account_balances' después de la eliminación:\n",
      "   id  code  accounting_id    name  initial_balance  final_balance  \\\n",
      "0   1   1.0              1  Activo              0.0  -4.500000e+04   \n",
      "1   2   1.0              1  Activo              0.0   3.550000e+06   \n",
      "2   3   1.0              1  Activo              0.0   0.000000e+00   \n",
      "3   4   1.0              1  Activo              0.0   3.730769e+03   \n",
      "4   5   1.0              1  Activo              0.0   2.781800e+04   \n",
      "\n",
      "   debit_movement  credit_movement third_party_type_id  third_party_id  year  \\\n",
      "0       3525000.0     3.570000e+06             Contact               1  2024   \n",
      "1       3570000.0     2.000000e+04             Contact               1  2024   \n",
      "2         59500.0     5.950000e+04             Contact              13  2024   \n",
      "3         59500.0     5.576923e+04             Contact              13  2024   \n",
      "4        149940.0     1.221220e+05             Contact              34  2024   \n",
      "\n",
      "   month  \n",
      "0      2  \n",
      "1      2  \n",
      "2      2  \n",
      "3      2  \n",
      "4      2  \n",
      "\n",
      "Proceso de eliminación de columnas completado.\n"
     ]
    }
   ],
   "source": [
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_account_balances' ---\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_account_balances'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_account_balances = pd.read_sql('SELECT * FROM accounting_account_balances', engine)\n",
    "    print(f\"Tabla 'accounting_account_balances' cargada exitosamente. Filas: {df_account_balances.shape[0]}, Columnas: {df_account_balances.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'accounting_account_balances': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Definir y eliminar las columnas ---\n",
    "print(\"\\nEliminando columnas 'created_at', 'updated_at', y 'currency_id'...\")\n",
    "\n",
    "columns_to_drop = ['created_at', 'updated_at', 'currency_id']\n",
    "\n",
    "# Usamos .drop() para eliminar las columnas.\n",
    "# `axis=1` indica que estamos eliminando columnas (no filas).\n",
    "# `inplace=True` modificaría el DataFrame original directamente.\n",
    "# Si quieres crear un nuevo DataFrame y mantener el original, omite `inplace=True`\n",
    "# y asigna el resultado a una nueva variable, por ejemplo:\n",
    "# df_account_balances_cleaned = df_account_balances.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "# Para este ejemplo, modificaremos el DataFrame original para que sigas trabajando con él\n",
    "df_account_balances.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(f\"Columnas {columns_to_drop} eliminadas exitosamente.\")\n",
    "\n",
    "# --- Paso 3: Verificar las columnas restantes ---\n",
    "print(f\"\\nColumnas restantes en el DataFrame 'accounting_account_balances':\")\n",
    "print(df_account_balances.columns.tolist())\n",
    "\n",
    "# --- Paso 4: Mostrar las primeras filas del DataFrame modificado ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame 'accounting_account_balances' después de la eliminación:\")\n",
    "print(df_account_balances.head())\n",
    "\n",
    "print(\"\\nProceso de eliminación de columnas completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a9686",
   "metadata": {},
   "source": [
    "Conversión de la tabla a formato csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44dd16ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- Paso 1: Recargar la tabla \\'accounting_account_balances\\' y aplicar las transformaciones ---\\n# Es CRUCIAL que el DataFrame refleje las últimas operaciones (ej. eliminación de columnas)\\n# Si tu script anterior ya dejó \\'df_account_balances\\' en el estado deseado, puedes omitir esta recarga y transformación.\\n# Sin embargo, para asegurar la reproducibilidad y que el CSV contenga el DataFrame limpio,\\n# es buena práctica recargar y aplicar las transformaciones si este es un script independiente.\\n\\nprint(\"Preparando el DataFrame \\'accounting_account_balances\\' para exportación...\")\\ntry:\\n    engine = get_engine()\\n    df_account_balances = pd.read_sql(\\'SELECT * FROM accounting_account_balances\\', engine)\\n\\n    # Aplicar las eliminaciones de columnas que definimos previamente\\n    columns_to_drop = [\\'created_at\\', \\'updated_at\\', \\'currency_id\\']\\n    # Filtrar solo las columnas que realmente existen en el DataFrame para evitar errores si ya fueron eliminadas\\n    existing_columns_to_drop = [col for col in columns_to_drop if col in df_account_balances.columns]\\n\\n    if existing_columns_to_drop:\\n        df_account_balances.drop(columns=existing_columns_to_drop, inplace=True)\\n        print(f\"Columnas {existing_columns_to_drop} eliminadas antes de exportar.\")\\n    else:\\n        print(\"Las columnas a eliminar (\\'created_at\\', \\'updated_at\\', \\'currency_id\\') no se encontraron o ya fueron eliminadas.\")\\n\\n    print(f\"DataFrame \\'accounting_account_balances\\' listo para exportación. Filas: {df_account_balances.shape[0]}, Columnas: {df_account_balances.shape[1]}\")\\n\\nexcept Exception as e:\\n    print(f\"Error al preparar el DataFrame \\'accounting_account_balances\\': {e}\")\\n    raise # Relanzar la excepción para detener la ejecución si falla.\\n\\n# --- Paso 2: Definir la ruta y el nombre del archivo CSV ---\\n# Puedes ajustar la ruta donde quieres guardar el archivo.\\n# \\'os.getcwd()\\' te da el directorio de trabajo actual donde se está ejecutando el script.\\noutput_directory = os.getcwd() # Guarda en el mismo directorio del script\\ncsv_filename = \\'accounting_account_balances_cleaned.csv\\'\\noutput_filepath = os.path.join(output_directory, csv_filename)\\n\\n# --- Paso 3: Exportar el DataFrame a un archivo CSV ---\\nprint(f\"\\nExportando el DataFrame a CSV: \\'{output_filepath}\\'...\")\\ntry:\\n    df_account_balances.to_csv(output_filepath, index=False, encoding=\\'utf-8\\')\\n    print(\"¡DataFrame exportado a CSV exitosamente!\")\\n    print(f\"Puedes encontrar el archivo en: {output_filepath}\")\\nexcept Exception as e:\\n    print(f\"Error al exportar el DataFrame a CSV: {e}\")\\n\\nprint(\"\\nProceso de exportación a CSV completado.\")'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# --- Paso 1: Recargar la tabla 'accounting_account_balances' y aplicar las transformaciones ---\n",
    "# Es CRUCIAL que el DataFrame refleje las últimas operaciones (ej. eliminación de columnas)\n",
    "# Si tu script anterior ya dejó 'df_account_balances' en el estado deseado, puedes omitir esta recarga y transformación.\n",
    "# Sin embargo, para asegurar la reproducibilidad y que el CSV contenga el DataFrame limpio,\n",
    "# es buena práctica recargar y aplicar las transformaciones si este es un script independiente.\n",
    "\n",
    "print(\"Preparando el DataFrame 'accounting_account_balances' para exportación...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_account_balances = pd.read_sql('SELECT * FROM accounting_account_balances', engine)\n",
    "    \n",
    "    # Aplicar las eliminaciones de columnas que definimos previamente\n",
    "    columns_to_drop = ['created_at', 'updated_at', 'currency_id']\n",
    "    # Filtrar solo las columnas que realmente existen en el DataFrame para evitar errores si ya fueron eliminadas\n",
    "    existing_columns_to_drop = [col for col in columns_to_drop if col in df_account_balances.columns]\n",
    "    \n",
    "    if existing_columns_to_drop:\n",
    "        df_account_balances.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "        print(f\"Columnas {existing_columns_to_drop} eliminadas antes de exportar.\")\n",
    "    else:\n",
    "        print(\"Las columnas a eliminar ('created_at', 'updated_at', 'currency_id') no se encontraron o ya fueron eliminadas.\")\n",
    "\n",
    "    print(f\"DataFrame 'accounting_account_balances' listo para exportación. Filas: {df_account_balances.shape[0]}, Columnas: {df_account_balances.shape[1]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al preparar el DataFrame 'accounting_account_balances': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla.\n",
    "\n",
    "# --- Paso 2: Definir la ruta y el nombre del archivo CSV ---\n",
    "# Puedes ajustar la ruta donde quieres guardar el archivo.\n",
    "# 'os.getcwd()' te da el directorio de trabajo actual donde se está ejecutando el script.\n",
    "output_directory = os.getcwd() # Guarda en el mismo directorio del script\n",
    "csv_filename = 'accounting_account_balances_cleaned.csv'\n",
    "output_filepath = os.path.join(output_directory, csv_filename)\n",
    "\n",
    "# --- Paso 3: Exportar el DataFrame a un archivo CSV ---\n",
    "print(f\"\\nExportando el DataFrame a CSV: '{output_filepath}'...\")\n",
    "try:\n",
    "    df_account_balances.to_csv(output_filepath, index=False, encoding='utf-8')\n",
    "    print(\"¡DataFrame exportado a CSV exitosamente!\")\n",
    "    print(f\"Puedes encontrar el archivo en: {output_filepath}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al exportar el DataFrame a CSV: {e}\")\n",
    "\n",
    "print(\"\\nProceso de exportación a CSV completado.\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b602a50",
   "metadata": {},
   "source": [
    "Tabla accounting_accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47a6d174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_accounts':\n",
      "  - id (bigint unsigned)\n",
      "  - name (varchar(250))\n",
      "  - is_class (tinyint(1))\n",
      "  - is_group (tinyint(1))\n",
      "  - is_account (tinyint(1))\n",
      "  - is_subaccount (tinyint(1))\n",
      "  - is_auxiliary (tinyint(1))\n",
      "  - is_subauxiliary (tinyint(1))\n",
      "  - niif (tinyint(1))\n",
      "  - cash_flow (tinyint(1))\n",
      "  - exogenous (tinyint(1))\n",
      "  - base_value (tinyint(1))\n",
      "  - nature (varchar(1))\n",
      "  - term (tinyint(1))\n",
      "  - favorite (tinyint(1))\n",
      "  - status (tinyint(1))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_accounts;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_accounts':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9bdeb",
   "metadata": {},
   "source": [
    "Detección de Columnas Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67456435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'accounting_accounts'...\n",
      "Tabla 'accounting_accounts' cargada exitosamente. Filas: 2125, Columnas: 18\n",
      "\n",
      "Identificando columnas con valores constantes en 'accounting_accounts'...\n",
      "\n",
      "Columnas con valores constantes identificadas en 'accounting_accounts':\n",
      "  - 'is_subauxiliary': Valor único = 0\n",
      "  - 'cash_flow': Valor único = 0\n",
      "  - 'exogenous': Valor único = 0\n",
      "  - 'base_value': Valor único = 0\n",
      "  - 'term': Valor único = 0\n",
      "  - 'favorite': Valor único = 0\n",
      "  - 'status': Valor único = 1\n",
      "\n",
      "Proceso de identificación de columnas constantes completado para 'accounting_accounts'.\n",
      "\n",
      "Primeras 5 filas del DataFrame 'accounting_accounts':\n",
      "   id        name  is_class  is_group  is_account  is_subaccount  \\\n",
      "0   1      Activo         1         0           0              0   \n",
      "1   2     Pasivos         1         0           0              0   \n",
      "2   3  Patrimonio         1         0           0              0   \n",
      "3   4    Ingresos         1         0           0              0   \n",
      "4   5      Gastos         1         0           0              0   \n",
      "\n",
      "   is_auxiliary  is_subauxiliary  niif  cash_flow  exogenous  base_value  \\\n",
      "0             0                0     1          0          0           0   \n",
      "1             0                0     1          0          0           0   \n",
      "2             0                0     1          0          0           0   \n",
      "3             0                0     1          0          0           0   \n",
      "4             0                0     1          0          0           0   \n",
      "\n",
      "  nature  term  favorite  status          created_at          updated_at  \n",
      "0      D     0         0       1 2024-03-27 12:07:39 2024-03-27 12:07:39  \n",
      "1      C     0         0       1 2024-03-27 12:07:39 2024-03-27 12:07:39  \n",
      "2      C     0         0       1 2024-03-27 12:07:39 2024-03-27 12:07:39  \n",
      "3      C     0         0       1 2024-03-27 12:07:39 2024-03-27 12:07:39  \n",
      "4      D     0         0       1 2024-03-27 12:07:39 2024-03-27 12:07:39  \n"
     ]
    }
   ],
   "source": [
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_accounts' ---\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_accounts'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_accounting_accounts = pd.read_sql('SELECT * FROM accounting_accounts', engine)\n",
    "    print(f\"Tabla 'accounting_accounts' cargada exitosamente. Filas: {df_accounting_accounts.shape[0]}, Columnas: {df_accounting_accounts.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'accounting_accounts': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Identificar columnas con valores constantes ---\n",
    "print(\"\\nIdentificando columnas con valores constantes en 'accounting_accounts'...\")\n",
    "\n",
    "constant_columns = []\n",
    "for col in df_accounting_accounts.columns:\n",
    "    # `nunique()` cuenta el número de valores únicos en una columna.\n",
    "    # Si es 1, significa que todos los valores son el mismo (constante).\n",
    "    if df_accounting_accounts[col].nunique() == 1:\n",
    "        constant_columns.append(col)\n",
    "\n",
    "if constant_columns:\n",
    "    print(f\"\\nColumnas con valores constantes identificadas en 'accounting_accounts':\")\n",
    "    for col in constant_columns:\n",
    "        print(f\"  - '{col}': Valor único = {df_accounting_accounts[col].iloc[0]}\") # Muestra el valor constante\n",
    "else:\n",
    "    print(\"No se encontraron columnas con valores constantes en la tabla 'accounting_accounts'.\")\n",
    "\n",
    "print(\"\\nProceso de identificación de columnas constantes completado para 'accounting_accounts'.\")\n",
    "\n",
    "# --- Opcional: Mostrar las primeras filas del DataFrame para referencia ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame 'accounting_accounts':\")\n",
    "print(df_accounting_accounts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b55d713",
   "metadata": {},
   "source": [
    "Eliminación de Columna Constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_accounts' ---\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_accounts'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_accounting_accounts = pd.read_sql('SELECT * FROM accounting_accounts', engine)\n",
    "    print(f\"Tabla 'accounting_accounts' cargada exitosamente. Filas: {df_accounting_accounts.shape[0]}, Columnas: {df_accounting_accounts.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'accounting_accounts': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Definir y eliminar las columnas constantes ---\n",
    "print(\"\\nEliminando columnas constantes de 'accounting_accounts'...\")\n",
    "\n",
    "# Lista de columnas identificadas como constantes\n",
    "columns_to_drop_constant = [\n",
    "    'is_subauxiliary',\n",
    "    'cash_flow',\n",
    "    'exogenous',\n",
    "    'base_value',\n",
    "    'term',\n",
    "    'favorite',\n",
    "    'status'\n",
    "]\n",
    "\n",
    "# Es buena práctica verificar que las columnas existen antes de intentar eliminarlas\n",
    "existing_columns_to_drop = [col for col in columns_to_drop_constant if col in df_accounting_accounts.columns]\n",
    "\n",
    "if existing_columns_to_drop:\n",
    "    df_accounting_accounts.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "    print(f\"Columnas {existing_columns_to_drop} eliminadas exitosamente.\")\n",
    "else:\n",
    "    print(\"Ninguna de las columnas constantes a eliminar se encontró en el DataFrame o ya fueron eliminadas.\")\n",
    "\n",
    "# --- Paso 3: Verificar las columnas restantes ---\n",
    "print(f\"\\nColumnas restantes en el DataFrame 'accounting_accounts':\")\n",
    "print(df_accounting_accounts.columns.tolist())\n",
    "\n",
    "# --- Paso 4: Mostrar las primeras filas del DataFrame modificado ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame 'accounting_accounts' después de la eliminación:\")\n",
    "print(df_accounting_accounts.head())\n",
    "\n",
    "print(\"\\nProceso de eliminación de columnas constantes completado para 'accounting_accounts'.\") \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd7b08e",
   "metadata": {},
   "source": [
    "Tabla accounting_movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69120ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_movements':\n",
      "  - id (bigint unsigned)\n",
      "  - class_id (bigint unsigned)\n",
      "  - group_id (bigint unsigned)\n",
      "  - account_id (bigint unsigned)\n",
      "  - subaccount_id (bigint unsigned)\n",
      "  - accounting_movement (bigint)\n",
      "  - currency_id (varchar(255))\n",
      "  - name (varchar(255))\n",
      "  - date (timestamp)\n",
      "  - debit_movement (double(18,6))\n",
      "  - credit_movement (double(18,6))\n",
      "  - third_party_type_id (varchar(50))\n",
      "  - third_party_id (int unsigned)\n",
      "  - document_type_id (smallint)\n",
      "  - document (varchar(255))\n",
      "  - document_id (bigint unsigned)\n",
      "  - item_type (varchar(255))\n",
      "  - item_id (int unsigned)\n",
      "  - references_document_id (bigint unsigned)\n",
      "  - payroll_employee_reference_id (int unsigned)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_movements;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_movements':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6951229",
   "metadata": {},
   "source": [
    "#Se identifica que hay datos faltantes en las columnas: o\treferences_document_id: 6019 nulos (85.74%)\n",
    "o\titem_id: 5511 nulos (78.50%)\n",
    "o\titem_type: 5511 nulos (78.50%)\n",
    "o\tdocument: 4510 nulos (64.25%)\n",
    "o\tpayroll_employee_reference_id: 2510 nulos (35.75%)\n",
    "\n",
    "-> Se identifica que las columnas item_type, item_id y references_document_id refieren a lo mismo, por lo cual, solo se llenaba una de las 3, siendo necesario combinar toda la información en una nueva columna\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d568f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'accounting_movements'...\n",
      "Tabla 'accounting_movements' cargada exitosamente. Filas: 7020, Columnas: 22\n",
      "\n",
      "Combinando columnas 'item_id', 'references_document_id', y 'payroll_employee_reference_id'...\n",
      "Columnas combinadas 'primary_reference_type' y 'primary_reference_id' creadas.\n",
      "Columnas originales ['item_id', 'references_document_id', 'payroll_employee_reference_id'] eliminadas.\n",
      "\n",
      "Primeras 5 filas del DataFrame con las nuevas columnas de referencia:\n",
      "  primary_reference_type  primary_reference_id\n",
      "0                   Item                 394.0\n",
      "1                   Item                 394.0\n",
      "2                   Item                 394.0\n",
      "3                   Item                 394.0\n",
      "4                   Item                 394.0\n",
      "\n",
      "Conteo de nulos para las nuevas columnas de referencia:\n",
      "primary_reference_type    0\n",
      "primary_reference_id      0\n",
      "dtype: int64\n",
      "\n",
      "Proceso de combinación de referencias completado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DUVAN\\AppData\\Local\\Temp\\ipykernel_14852\\1707058357.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Payroll Employee' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_accounting_movements.loc[cond_payroll, 'primary_reference_type'] = 'Payroll Employee'\n"
     ]
    }
   ],
   "source": [
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_movements' ---\n",
    "# *** IMPORTANTE: Si ya ejecutaste el código anterior, asegúrate de recargar el DataFrame ***\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_movements'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_accounting_movements = pd.read_sql('SELECT * FROM accounting_movements', engine)\n",
    "    print(f\"Tabla 'accounting_movements' cargada exitosamente. Filas: {df_accounting_movements.shape[0]}, Columnas: {df_accounting_movements.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'accounting_movements': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Crear las nuevas columnas combinadas ---\n",
    "print(\"\\nCombinando columnas 'item_id', 'references_document_id', y 'payroll_employee_reference_id'...\")\n",
    "\n",
    "# Inicializar las nuevas columnas con valores nulos\n",
    "df_accounting_movements['primary_reference_type'] = np.nan\n",
    "df_accounting_movements['primary_reference_id'] = np.nan\n",
    "\n",
    "# Lógica de combinación con prioridad:\n",
    "# 1. payroll_employee_reference_id (más específico)\n",
    "# 2. references_document_id\n",
    "# 3. item_id\n",
    "\n",
    "# Condición 1: Cuando payroll_employee_reference_id tiene un valor\n",
    "cond_payroll = df_accounting_movements['payroll_employee_reference_id'].notna()\n",
    "df_accounting_movements.loc[cond_payroll, 'primary_reference_type'] = 'Payroll Employee'\n",
    "df_accounting_movements.loc[cond_payroll, 'primary_reference_id'] = df_accounting_movements['payroll_employee_reference_id']\n",
    "\n",
    "# Condición 2: Cuando payroll_employee_reference_id es nulo, pero references_document_id no lo es\n",
    "cond_doc = (~cond_payroll) & (df_accounting_movements['references_document_id'].notna())\n",
    "df_accounting_movements.loc[cond_doc, 'primary_reference_type'] = 'Document'\n",
    "df_accounting_movements.loc[cond_doc, 'primary_reference_id'] = df_accounting_movements['references_document_id']\n",
    "\n",
    "# Condición 3: Cuando payroll_employee_reference_id y references_document_id son nulos, pero item_id no lo es\n",
    "cond_item = (~cond_payroll) & (~cond_doc) & (df_accounting_movements['item_id'].notna())\n",
    "df_accounting_movements.loc[cond_item, 'primary_reference_type'] = 'Item'\n",
    "df_accounting_movements.loc[cond_item, 'primary_reference_id'] = df_accounting_movements['item_id']\n",
    "\n",
    "# Para los casos donde ninguna de las referencias se llenó, primary_reference_type e _id quedarán como NaN.\n",
    "# Rellenar 'primary_reference_type' con 'N/A' para mayor claridad\n",
    "df_accounting_movements['primary_reference_type'] = df_accounting_movements['primary_reference_type'].fillna('N/A')\n",
    "\n",
    "print(\"Columnas combinadas 'primary_reference_type' y 'primary_reference_id' creadas.\")\n",
    "\n",
    "# --- Paso 3: Opcional - Eliminar las columnas originales si ya no son necesarias ---\n",
    "# Asegúrate de que las columnas 'item_type' y 'document' (de las que hablamos en la revisión anterior)\n",
    "# también se incluyan aquí si no las necesitas más, ya que también tenían muchos nulos.\n",
    "# Aquí solo estoy eliminando las que pediste combinar.\n",
    "columns_to_drop = ['item_id', 'references_document_id', 'payroll_employee_reference_id']\n",
    "# Si también quieres eliminar 'item_type' y 'document' (de la discusión previa), descomenta la línea de abajo:\n",
    "# columns_to_drop.extend(['item_type', 'document'])\n",
    "\n",
    "df_accounting_movements_cleaned = df_accounting_movements.drop(columns=columns_to_drop)\n",
    "print(f\"Columnas originales {columns_to_drop} eliminadas.\")\n",
    "\n",
    "# --- Paso 4: Mostrar las primeras filas con las nuevas columnas ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame con las nuevas columnas de referencia:\")\n",
    "print(df_accounting_movements_cleaned[['primary_reference_type', 'primary_reference_id']].head())\n",
    "\n",
    "# --- Paso 5: Verificar el conteo de nulos para las nuevas columnas ---\n",
    "print(\"\\nConteo de nulos para las nuevas columnas de referencia:\")\n",
    "print(df_accounting_movements_cleaned[['primary_reference_type', 'primary_reference_id']].isnull().sum())\n",
    "\n",
    "print(\"\\nProceso de combinación de referencias completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "474d7927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'accounting_movements'...\n",
      "Tabla 'accounting_movements' cargada exitosamente. Filas: 7020, Columnas: 22\n",
      "\n",
      "Combinando columnas 'item_id', 'references_document_id', y 'payroll_employee_reference_id'...\n",
      "Columnas combinadas 'primary_reference_type' y 'primary_reference_id' creadas.\n",
      "Columnas originales ['item_id', 'references_document_id', 'payroll_employee_reference_id', 'item_type'] eliminadas.\n",
      "\n",
      "Primeras 5 filas del DataFrame con las nuevas columnas de referencia:\n",
      "   id primary_reference_type  primary_reference_id\n",
      "0  74                   Item                 394.0\n",
      "1  75                   Item                 394.0\n",
      "2  76                   Item                 394.0\n",
      "3  77                   Item                 394.0\n",
      "4  78                   Item                 394.0\n",
      "\n",
      "Conteo de nulos para las nuevas columnas de referencia:\n",
      "primary_reference_type    0\n",
      "primary_reference_id      0\n",
      "dtype: int64\n",
      "\n",
      "Columnas restantes en el DataFrame después de la limpieza: ['id', 'class_id', 'group_id', 'account_id', 'subaccount_id', 'accounting_movement', 'currency_id', 'name', 'date', 'debit_movement', 'credit_movement', 'third_party_type_id', 'third_party_id', 'document_type_id', 'document', 'document_id', 'created_at', 'updated_at', 'primary_reference_type', 'primary_reference_id']\n",
      "\n",
      "Proceso de combinación de referencias y eliminación de 'item_type' completado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DUVAN\\AppData\\Local\\Temp\\ipykernel_14852\\289087782.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Payroll Employee' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_accounting_movements.loc[cond_payroll, 'primary_reference_type'] = 'Payroll Employee'\n"
     ]
    }
   ],
   "source": [
    "# Asegúrate de que get_engine() está definida en db_connection.py\n",
    "from db_connection import get_engine\n",
    "\n",
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_movements' ---\n",
    "# *** IMPORTANTE: Si ya ejecutaste el código anterior, asegúrate de recargar el DataFrame ***\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_movements'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_accounting_movements = pd.read_sql('SELECT * FROM accounting_movements', engine)\n",
    "    print(f\"Tabla 'accounting_movements' cargada exitosamente. Filas: {df_accounting_movements.shape[0]}, Columnas: {df_accounting_movements.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'accounting_movements': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Crear las nuevas columnas combinadas ---\n",
    "print(\"\\nCombinando columnas 'item_id', 'references_document_id', y 'payroll_employee_reference_id'...\")\n",
    "\n",
    "# Inicializar las nuevas columnas con valores nulos\n",
    "df_accounting_movements['primary_reference_type'] = np.nan\n",
    "df_accounting_movements['primary_reference_id'] = np.nan\n",
    "\n",
    "# Lógica de combinación con prioridad:\n",
    "# 1. payroll_employee_reference_id (más específico)\n",
    "# 2. references_document_id\n",
    "# 3. item_id\n",
    "\n",
    "# Condición 1: Cuando payroll_employee_reference_id tiene un valor\n",
    "cond_payroll = df_accounting_movements['payroll_employee_reference_id'].notna()\n",
    "df_accounting_movements.loc[cond_payroll, 'primary_reference_type'] = 'Payroll Employee'\n",
    "df_accounting_movements.loc[cond_payroll, 'primary_reference_id'] = df_accounting_movements['payroll_employee_reference_id']\n",
    "\n",
    "# Condición 2: Cuando payroll_employee_reference_id es nulo, pero references_document_id no lo es\n",
    "cond_doc = (~cond_payroll) & (df_accounting_movements['references_document_id'].notna())\n",
    "df_accounting_movements.loc[cond_doc, 'primary_reference_type'] = 'Document'\n",
    "df_accounting_movements.loc[cond_doc, 'primary_reference_id'] = df_accounting_movements['references_document_id']\n",
    "\n",
    "# Condición 3: Cuando payroll_employee_reference_id y references_document_id son nulos, pero item_id no lo es\n",
    "cond_item = (~cond_payroll) & (~cond_doc) & (df_accounting_movements['item_id'].notna())\n",
    "df_accounting_movements.loc[cond_item, 'primary_reference_type'] = 'Item'\n",
    "df_accounting_movements.loc[cond_item, 'primary_reference_id'] = df_accounting_movements['item_id']\n",
    "\n",
    "# Para los casos donde ninguna de las referencias se llenó, primary_reference_type e _id quedarán como NaN.\n",
    "# Rellenar 'primary_reference_type' con 'N/A' para mayor claridad\n",
    "df_accounting_movements['primary_reference_type'] = df_accounting_movements['primary_reference_type'].fillna('N/A')\n",
    "\n",
    "print(\"Columnas combinadas 'primary_reference_type' y 'primary_reference_id' creadas.\")\n",
    "\n",
    "# --- Paso 3: Opcional - Eliminar las columnas originales si ya no son necesarias ---\n",
    "# *** Hemos añadido 'item_type' a la lista de columnas a eliminar ***\n",
    "columns_to_drop = ['item_id', 'references_document_id', 'payroll_employee_reference_id', 'item_type']\n",
    "\n",
    "df_accounting_movements_cleaned = df_accounting_movements.drop(columns=columns_to_drop)\n",
    "print(f\"Columnas originales {columns_to_drop} eliminadas.\")\n",
    "\n",
    "# --- Paso 4: Mostrar las primeras filas con las nuevas columnas ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame con las nuevas columnas de referencia:\")\n",
    "# Ajusta las columnas a mostrar en head() si quieres ver otras además de las nuevas de referencia\n",
    "print(df_accounting_movements_cleaned[['id', 'primary_reference_type', 'primary_reference_id']].head())\n",
    "\n",
    "# --- Paso 5: Verificar el conteo de nulos para las nuevas columnas ---\n",
    "print(\"\\nConteo de nulos para las nuevas columnas de referencia:\")\n",
    "print(df_accounting_movements_cleaned[['primary_reference_type', 'primary_reference_id']].isnull().sum())\n",
    "\n",
    "# --- Paso 6: Verificar que item_type ha sido eliminada ---\n",
    "print(f\"\\nColumnas restantes en el DataFrame después de la limpieza: {df_accounting_movements_cleaned.columns.tolist()}\")\n",
    "\n",
    "print(\"\\nProceso de combinación de referencias y eliminación de 'item_type' completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db740e1a",
   "metadata": {},
   "source": [
    "Tabla accounting_voucher_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2ccc01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_voucher_items':\n",
      "  - id (bigint unsigned)\n",
      "  - accounting_voucher_id (bigint unsigned)\n",
      "  - third_party_type_id (varchar(255))\n",
      "  - third_party_id (bigint unsigned)\n",
      "  - accounting_account_id (bigint unsigned)\n",
      "  - description (varchar(255))\n",
      "  - debit_movement (double(18,6))\n",
      "  - credit_movement (double(18,6))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n",
      "Conexión y cursor cerrados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_voucher_items;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_voucher_items':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "finally:\n",
    "    # 3. Cerrar el cursor y la conexión de forma segura\n",
    "    if 'cursor' in locals() and cursor is not None:\n",
    "        cursor.close()\n",
    "    if 'conexion' in locals() and conexion.is_connected():\n",
    "        conexion.close()\n",
    "    print(\"Conexión y cursor cerrados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96a304",
   "metadata": {},
   "source": [
    "Tabla accounting_vouchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f1b1d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_vouchers':\n",
      "  - id (bigint unsigned)\n",
      "  - accounting_voucher_type_id (bigint unsigned)\n",
      "  - prefix (varchar(50))\n",
      "  - number (bigint)\n",
      "  - voucher_date (date)\n",
      "  - third_party_id (bigint unsigned)\n",
      "  - third_party_type_id (varchar(50))\n",
      "  - advance_account_payable_id (bigint unsigned)\n",
      "  - supplier_account_id (bigint unsigned)\n",
      "  - advance_account_receivable_id (bigint unsigned)\n",
      "  - cartera_account_id (bigint unsigned)\n",
      "  - currency_id (varchar(255))\n",
      "  - total_value (double(18,6))\n",
      "  - voucher_status_id (smallint unsigned)\n",
      "  - preferred (tinyint(1))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n",
      "Conexión y cursor cerrados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_vouchers;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_vouchers':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "finally:\n",
    "    # 3. Cerrar el cursor y la conexión de forma segura\n",
    "    if 'cursor' in locals() and cursor is not None:\n",
    "        cursor.close()\n",
    "    if 'conexion' in locals() and conexion.is_connected():\n",
    "        conexion.close()\n",
    "    print(\"Conexión y cursor cerrados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f1ac6",
   "metadata": {},
   "source": [
    "Tabla accounting_voucher_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e70cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_voucher_types':\n",
      "  - id (bigint unsigned)\n",
      "  - code (varchar(50))\n",
      "  - name (varchar(60))\n",
      "  - prefix (varchar(50))\n",
      "  - initial_number (bigint)\n",
      "  - current_number (bigint)\n",
      "  - ledger_id (int unsigned)\n",
      "  - status (tinyint(1))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n",
      "Conexión y cursor cerrados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_voucher_types;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_voucher_types':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "finally:\n",
    "    # 3. Cerrar el cursor y la conexión de forma segura\n",
    "    if 'cursor' in locals() and cursor is not None:\n",
    "        cursor.close()\n",
    "    if 'conexion' in locals() and conexion.is_connected():\n",
    "        conexion.close()\n",
    "    print(\"Conexión y cursor cerrados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c1c7c",
   "metadata": {},
   "source": [
    "Tabla retention_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89d094c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'retention_concepts':\n",
      "  - id (int unsigned)\n",
      "  - description (text)\n",
      "  - account_id (bigint unsigned)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE retention_concepts;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'retention_concepts':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ca10f",
   "metadata": {},
   "source": [
    "Tabla retentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "367e7c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'retentions':\n",
      "  - id (int unsigned)\n",
      "  - retention_type_id (varchar(255))\n",
      "  - retention_concept (int unsigned)\n",
      "  - description (varchar(255))\n",
      "  - percentage (double(10,5))\n",
      "  - uvt_base (double(18,6))\n",
      "  - base (double(18,6))\n",
      "  - notes (varchar(255))\n",
      "  - status (tinyint(1))\n",
      "  - account_id (bigint unsigned)\n",
      "  - user_id (int unsigned)\n",
      "  - is_custom (varchar(255))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE retentions;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'retentions':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b6a0a",
   "metadata": {},
   "source": [
    "Tabla retentions_applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42084fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'retentions_applied':\n",
      "  - id (bigint unsigned)\n",
      "  - name (varchar(255))\n",
      "  - type (varchar(255))\n",
      "  - percentage (double(18,6))\n",
      "  - base (double(18,6))\n",
      "  - value (double(18,6))\n",
      "  - retention_id (int unsigned)\n",
      "  - contact_id (int unsigned)\n",
      "  - document_id (bigint unsigned)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE retentions_applied;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'retentions_applied':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd6ee3",
   "metadata": {},
   "source": [
    "Tabla retentions_certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d862148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'retentions_certificates':\n",
      "  - id (bigint unsigned)\n",
      "  - contact_id (int unsigned)\n",
      "  - document_id (bigint unsigned)\n",
      "  - value (double(18,6))\n",
      "  - sent (tinyint(1))\n",
      "  - certificate_url (varchar(255))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE retentions_certificates;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'retentions_certificates':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44c4bd",
   "metadata": {},
   "source": [
    "Tabla taxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23f500b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'taxes':\n",
      "  - id (smallint unsigned)\n",
      "  - tax_type_id (varchar(255))\n",
      "  - description (varchar(255))\n",
      "  - percentage (double(10,5))\n",
      "  - notes (varchar(255))\n",
      "  - status (tinyint(1))\n",
      "  - tax_account_deductible_id (bigint unsigned)\n",
      "  - tax_account_generated_id (bigint unsigned)\n",
      "  - user_id (int unsigned)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE taxes;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'taxes':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2f4b2",
   "metadata": {},
   "source": [
    "Tabla payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0d10b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'payments':\n",
      "  - id (bigint unsigned)\n",
      "  - document_type_id (int unsigned)\n",
      "  - billing_numbering_id (int unsigned)\n",
      "  - payment_type (smallint unsigned)\n",
      "  - contact_id (int unsigned)\n",
      "  - number (int unsigned)\n",
      "  - document_date (date)\n",
      "  - document_hour (time)\n",
      "  - associate_invoice (tinyint(1))\n",
      "  - reference_document (json)\n",
      "  - advance (tinyint(1))\n",
      "  - subtotal (double(16,2))\n",
      "  - discount (double(16,2))\n",
      "  - gross (double(16,2))\n",
      "  - pending (double(16,2))\n",
      "  - total (double(16,2))\n",
      "  - taxes (json)\n",
      "  - retentions_value (double(16,2))\n",
      "  - retentions (json)\n",
      "  - retentions_details (json)\n",
      "  - payments (json)\n",
      "  - notes (varchar(255))\n",
      "  - comments (varchar(255))\n",
      "  - document_status_id (smallint unsigned)\n",
      "  - DIAN_status (json)\n",
      "  - contact_data (json)\n",
      "  - details (json)\n",
      "  - extra_data (json)\n",
      "  - user_id (int unsigned)\n",
      "  - deleted_at (timestamp)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n",
      "Conexión y cursor cerrados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE payments;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'payments':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "finally:\n",
    "    # 3. Cerrar el cursor y la conexión de forma segura\n",
    "    if 'cursor' in locals() and cursor is not None:\n",
    "        cursor.close()\n",
    "    if 'conexion' in locals() and conexion.is_connected():\n",
    "        conexion.close()\n",
    "    print(\"Conexión y cursor cerrados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6528f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'payments'...\n",
      "Tabla 'payments' cargada exitosamente. Filas: 614, Columnas: 32\n",
      "\n",
      "Iniciando aplanamiento de columnas JSON...\n",
      "Aplanando columna: 'reference_document'\n",
      "Columna 'reference_document' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'taxes'\n",
      "Columna 'taxes' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'retentions'\n",
      "Columna 'retentions' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'retentions_details'\n",
      "Columna 'retentions_details' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'payments'\n",
      "Columna 'payments' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'DIAN_status'\n",
      "Columna 'DIAN_status' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'contact_data'\n",
      "Columna 'contact_data' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'details'\n",
      "Columna 'details' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'extra_data'\n",
      "ADVERTENCIA: No se pudo aplanar la columna 'extra_data' completamente. Error: Unable to allocate 182. MiB for an array with shape (14, 1704763) and data type int64\n",
      "Revisar la estructura JSON de 'extra_data' para un aplanamiento específico o manejar errores.\n",
      "\n",
      "Aplanamiento de campos JSON completado.\n",
      "Nuevo tamaño del DataFrame \"df_payments_flattened\": 7287 filas, 157 columnas.\n",
      "\n",
      "Primeras 5 filas del DataFrame 'df_payments_flattened':\n",
      "   id  document_type_id  billing_numbering_id  payment_type  contact_id  \\\n",
      "0   1                13                     3             0           2   \n",
      "1   2                13                     3             0           1   \n",
      "2   3                13                     3             0           7   \n",
      "3   4                13                     3             0           7   \n",
      "4   5                13                     3             0           1   \n",
      "\n",
      "   number document_date   document_hour  associate_invoice  advance  ...  \\\n",
      "0       1    2019-10-16 0 days 04:12:41                  1        0  ...   \n",
      "1       2    2019-10-16 0 days 05:56:17                  1        0  ...   \n",
      "2       3    2019-10-24 0 days 03:58:54                  1        0  ...   \n",
      "3       4    2019-10-24 0 days 04:00:50                  1        0  ...   \n",
      "4       5    2019-11-05 0 days 08:38:48                  1        0  ...   \n",
      "\n",
      "   details_retentions  details_discountValue  details_taxPercentage  \\\n",
      "0                 NaN                    NaN                    NaN   \n",
      "1                 NaN                    NaN                    NaN   \n",
      "2                 NaN                    NaN                    NaN   \n",
      "3                 NaN                    NaN                    NaN   \n",
      "4                 NaN                    NaN                    NaN   \n",
      "\n",
      "   details_unitSalePrice  details_taxDescription  details_discountPercentage  \\\n",
      "0                    NaN                     NaN                         NaN   \n",
      "1                    NaN                     NaN                         NaN   \n",
      "2                    NaN                     NaN                         NaN   \n",
      "3                    NaN                     NaN                         NaN   \n",
      "4                    NaN                     NaN                         NaN   \n",
      "\n",
      "  details_unitSalePriceNoTax details_headquarter  details_paymentAccount.id  \\\n",
      "0                        NaN                 NaN                        NaN   \n",
      "1                        NaN                 NaN                        NaN   \n",
      "2                        NaN                 NaN                        NaN   \n",
      "3                        NaN                 NaN                        NaN   \n",
      "4                        NaN                 NaN                        NaN   \n",
      "\n",
      "  details_paymentAccount.name  \n",
      "0                         NaN  \n",
      "1                         NaN  \n",
      "2                         NaN  \n",
      "3                         NaN  \n",
      "4                         NaN  \n",
      "\n",
      "[5 rows x 157 columns]\n",
      "\n",
      "Nuevas columnas añadidas (prefijadas por el nombre de la columna JSON original):\n",
      "['extra_data', 'reference_document_date', 'reference_document_total', 'reference_document_prefix', 'reference_document_invoice', 'reference_document_document_type_id', 'reference_document_billing_numbering_id', 'reference_document_document_id', 'taxes__id', 'taxes_base', 'taxes_type', 'taxes_value', 'taxes_percentage', 'taxes_description', 'retentions__id', 'retentions_base', 'retentions_type', 'retentions_value_retentions_dup', 'retentions_percentage', 'retentions_description', 'retentions_items', 'retentions_typeName', 'retentions_fromPayment', 'retentions_retentionId', 'retentions_details__id', 'retentions_details_base', 'retentions_details_type', 'retentions_details_value', 'retentions_details_typeName', 'retentions_details_percentage', 'retentions_details_description', 'retentions_details_retentionId', 'retentions_details_fromPayment', 'retentions_details_items', 'payments_value', 'payments_paymentMethodId', 'payments_paymentMethodDescription', 'payments_paymentReference', 'payments_affectedInvoices', 'payments_paymentAccount.id', 'payments_paymentAccount.name', 'payments_paymentValue', 'DIAN_status_date', 'DIAN_status_message', 'DIAN_status_status_id', 'contact_data_id', 'contact_data_city', 'contact_data_lead', 'contact_data_email', 'contact_data_group', 'contact_data_names', 'contact_data_notes', 'contact_data_phone', 'contact_data_client', 'contact_data_mobile', 'contact_data_region', 'contact_data_status', 'contact_data_address', 'contact_data_country', 'contact_data_user_id', 'contact_data_provider', 'contact_data_surnames', 'contact_data_zip_code', 'contact_data_extension', 'contact_data_full_name', 'contact_data_tenant_id', 'contact_data_created_at', 'contact_data_deleted_at', 'contact_data_updated_at', 'contact_data_check_digit', 'contact_data_obligations', 'contact_data_neighborhood', 'contact_data_business_name', 'contact_data_register_type', 'contact_data_person_type_id', 'contact_data_document_number', 'contact_data_iva_responsible', 'contact_data_economic_activity', 'contact_data_payment_condition_id', 'contact_data_tax_responsibility_id', 'contact_data_contributory_scheme_id', 'contact_data_identity_document_type_id', 'contact_data_tradename', 'contact_data_price_list_id', 'contact_data_max_billing_value', 'contact_data_photo', 'contact_data_e_user', 'contact_data_e_status', 'contact_data_dial_code', 'contact_data_main_contact', 'contact_data_from_ecommerce', 'contact_data_shipping_address', 'contact_data_e_register_source', 'contact_data_address_complement', 'contact_data_headquarter_id', 'contact_data_external_id', 'contact_data_national', 'contact_data_gender_id', 'contact_data_is_own_tenant_provider', 'details_id', 'details_paid', 'details_total', 'details_credit', 'details_number', 'details_prefix', 'details_pending', 'details_paymentValue', 'details_gross', 'details_index', 'details_ivaTotal', 'details_retentionsValue', 'details_aTotalRetentions', 'details_electronicBilling', 'details_prevRetentionsValue', 'details_prevTotalRetentions', 'details_aTotalRetentionsDetails', 'details_prevTotalRetentionsDetails', 'details_name', 'details_notes', 'details_taxId', 'details_taxType', 'details_quantity', 'details_taxTotal', 'details_taxValue', 'details_retentions', 'details_discountValue', 'details_taxPercentage', 'details_unitSalePrice', 'details_taxDescription', 'details_discountPercentage', 'details_unitSalePriceNoTax', 'details_headquarter', 'details_paymentAccount.id', 'details_paymentAccount.name']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import json # Necesario para parsear strings JSON si no son objetos nativos\n",
    "\n",
    "# Asegúrate de que get_engine() está definida en db_connection.py\n",
    "from db_connection import get_engine\n",
    "\n",
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'payments' ---\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'payments'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_payments = pd.read_sql('SELECT * FROM payments', engine)\n",
    "    print(f\"Tabla 'payments' cargada exitosamente. Filas: {df_payments.shape[0]}, Columnas: {df_payments.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'payments': {e}\")\n",
    "    # Considera salir o manejar el error adecuadamente si la carga falla\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Identificar columnas JSON y aplanarlas ---\n",
    "# Definimos las columnas que identificamos como JSON\n",
    "json_columns = [\n",
    "    'reference_document',\n",
    "    'taxes',\n",
    "    'retentions',\n",
    "    'retentions_details',\n",
    "    'payments', # Ojo: esta es la columna 'payments' en la tabla 'payments'.\n",
    "    'DIAN_status',\n",
    "    'contact_data',\n",
    "    'details',\n",
    "    'extra_data'\n",
    "]\n",
    "\n",
    "# Crear una copia del DataFrame para trabajar y mantener el original si es necesario\n",
    "df_payments_flattened = df_payments.copy()\n",
    "\n",
    "print(\"\\nIniciando aplanamiento de columnas JSON...\")\n",
    "\n",
    "for col in json_columns:\n",
    "    if col in df_payments_flattened.columns:\n",
    "        print(f\"Aplanando columna: '{col}'\")\n",
    "        \n",
    "        # Convertir strings JSON a objetos Python (si no lo son ya)\n",
    "        # Usamos .astype(str) para asegurar que el contenido sea string antes de json.loads,\n",
    "        # lo que puede ayudar si hay valores no-string (ej., números)\n",
    "        df_payments_flattened[col] = df_payments_flattened[col].astype(str).apply(\n",
    "            lambda x: json.loads(x) if isinstance(x, str) and x.strip() and x.startswith(('[', '{')) else None\n",
    "        )\n",
    "\n",
    "        # Filtrar solo las filas donde el JSON no es nulo y es un diccionario/lista\n",
    "        valid_json_data = df_payments_flattened[df_payments_flattened[col].apply(lambda x: isinstance(x, (dict, list)) and x is not None)][col]\n",
    "        \n",
    "        # Obtener los índices de las filas con JSON válido para unir correctamente\n",
    "        valid_indices = valid_json_data.index\n",
    "\n",
    "        if not valid_json_data.empty:\n",
    "            try:\n",
    "                # Comprobar si el JSON es una lista (para aplanamiento de múltiples registros por ID)\n",
    "                # O si es un diccionario (para aplanamiento de claves a columnas)\n",
    "                \n",
    "                # Para el caso de 'payments' (la columna, no la tabla) o cualquier otra que sea una lista de objetos:\n",
    "                if valid_json_data.apply(lambda x: isinstance(x, list)).any():\n",
    "                    # Explode la lista de JSONs en múltiples filas, manteniendo el ID original.\n",
    "                    # Esto es útil si un solo registro de pago tiene múltiples sub-pagos o ítems.\n",
    "                    # Crea un DataFrame temporal para la columna JSON aplanada\n",
    "                    temp_df = pd.json_normalize(valid_json_data.explode())\n",
    "                    temp_df.index = valid_json_data.explode().index # Asegurar que el índice coincida\n",
    "                    \n",
    "                    # Unir con el DataFrame principal. Añadir un prefijo claro.\n",
    "                    df_payments_flattened = df_payments_flattened.merge(\n",
    "                        temp_df.add_prefix(f'{col}_'),\n",
    "                        left_index=True,\n",
    "                        right_index=True,\n",
    "                        how='left',\n",
    "                        suffixes=('', f'_{col}_dup') # Sufijo para columnas duplicadas, si las hay\n",
    "                    )\n",
    "                else: # Asumir que es un diccionario o un solo objeto JSON\n",
    "                    # Aplanar el diccionario.\n",
    "                    # Se usa `record_path=None` si el JSON de la columna es un diccionario con las claves a aplanar.\n",
    "                    df_col_flattened = pd.json_normalize(valid_json_data)\n",
    "                    df_col_flattened.index = valid_indices # Mantener el índice original\n",
    "\n",
    "                    # Unir con el DataFrame original por el índice (id del pago)\n",
    "                    df_payments_flattened = df_payments_flattened.merge(\n",
    "                        df_col_flattened.add_prefix(f'{col}_'),\n",
    "                        left_index=True,\n",
    "                        right_index=True,\n",
    "                        how='left',\n",
    "                        suffixes=('', f'_{col}_dup')\n",
    "                    )\n",
    "\n",
    "                # Eliminar la columna original después de aplanarla\n",
    "                df_payments_flattened = df_payments_flattened.drop(columns=[col])\n",
    "                print(f\"Columna '{col}' aplanada y eliminada. Nuevas columnas añadidas.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ADVERTENCIA: No se pudo aplanar la columna '{col}' completamente. Error: {e}\")\n",
    "                print(f\"Revisar la estructura JSON de '{col}' para un aplanamiento específico o manejar errores.\")\n",
    "        else:\n",
    "            print(f\"La columna '{col}' no contiene datos JSON válidos o no es un diccionario/lista en las filas seleccionadas.\")\n",
    "    else:\n",
    "        print(f\"La columna '{col}' no existe en el DataFrame original. Saltando.\")\n",
    "\n",
    "\n",
    "print(\"\\nAplanamiento de campos JSON completado.\")\n",
    "# La línea corregida para el SyntaxError:\n",
    "print(f\"Nuevo tamaño del DataFrame \\\"df_payments_flattened\\\": {df_payments_flattened.shape[0]} filas, {df_payments_flattened.shape[1]} columnas.\")\n",
    "\n",
    "# --- Paso 3: Mostrar las primeras filas del DataFrame aplanado para verificar ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame 'df_payments_flattened':\")\n",
    "print(df_payments_flattened.head())\n",
    "\n",
    "# --- Paso 4: Mostrar las nuevas columnas creadas ---\n",
    "print(\"\\nNuevas columnas añadidas (prefijadas por el nombre de la columna JSON original):\")\n",
    "# Obtener las columnas antes de aplanar (excluyendo las originales JSON que se eliminaron)\n",
    "initial_non_json_cols = [c for c in df_payments.columns if c not in json_columns]\n",
    "new_cols = [col for col in df_payments_flattened.columns if col not in initial_non_json_cols]\n",
    "print(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44791e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'payments':\n",
      "  - id (bigint unsigned)\n",
      "  - document_type_id (int unsigned)\n",
      "  - billing_numbering_id (int unsigned)\n",
      "  - payment_type (smallint unsigned)\n",
      "  - contact_id (int unsigned)\n",
      "  - number (int unsigned)\n",
      "  - document_date (date)\n",
      "  - document_hour (time)\n",
      "  - associate_invoice (tinyint(1))\n",
      "  - reference_document (json)\n",
      "  - advance (tinyint(1))\n",
      "  - subtotal (double(16,2))\n",
      "  - discount (double(16,2))\n",
      "  - gross (double(16,2))\n",
      "  - pending (double(16,2))\n",
      "  - total (double(16,2))\n",
      "  - taxes (json)\n",
      "  - retentions_value (double(16,2))\n",
      "  - retentions (json)\n",
      "  - retentions_details (json)\n",
      "  - payments (json)\n",
      "  - notes (varchar(255))\n",
      "  - comments (varchar(255))\n",
      "  - document_status_id (smallint unsigned)\n",
      "  - DIAN_status (json)\n",
      "  - contact_data (json)\n",
      "  - details (json)\n",
      "  - extra_data (json)\n",
      "  - user_id (int unsigned)\n",
      "  - deleted_at (timestamp)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n",
      "Conexión y cursor cerrados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE payments;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'payments':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "finally:\n",
    "    # 3. Cerrar el cursor y la conexión de forma segura\n",
    "    if 'cursor' in locals() and cursor is not None:\n",
    "        cursor.close()\n",
    "    if 'conexion' in locals() and conexion.is_connected():\n",
    "        conexion.close()\n",
    "    print(\"Conexión y cursor cerrados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347b390",
   "metadata": {},
   "source": [
    "GLOBAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c50b7138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos para revisar datos faltantes...\n",
      "Conexión a la base de datos establecida.\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'accounting_account_balances' ---\n",
      "No se encontraron valores faltantes en la tabla 'accounting_account_balances'.\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'accounting_accounts' ---\n",
      "No se encontraron valores faltantes en la tabla 'accounting_accounts'.\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'accounting_movements' ---\n",
      "Valores faltantes por columna:\n",
      "                               Missing Count  Missing Percentage\n",
      "references_document_id                  6019           85.740741\n",
      "item_id                                 5511           78.504274\n",
      "item_type                               5511           78.504274\n",
      "document                                4510           64.245014\n",
      "payroll_employee_reference_id           2510           35.754986\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'accounting_voucher_items' ---\n",
      "No se encontraron valores faltantes en la tabla 'accounting_voucher_items'.\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'accounting_voucher_types' ---\n",
      "Valores faltantes por columna:\n",
      "           Missing Count  Missing Percentage\n",
      "ledger_id             19                95.0\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'accounting_vouchers' ---\n",
      "Valores faltantes por columna:\n",
      "                               Missing Count  Missing Percentage\n",
      "third_party_id                             9           81.818182\n",
      "third_party_type_id                        9           81.818182\n",
      "advance_account_payable_id                 5           45.454545\n",
      "supplier_account_id                        5           45.454545\n",
      "advance_account_receivable_id              5           45.454545\n",
      "cartera_account_id                         5           45.454545\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'retention_concepts' ---\n",
      "No se encontraron valores faltantes en la tabla 'retention_concepts'.\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'retentions' ---\n",
      "Valores faltantes por columna:\n",
      "                   Missing Count  Missing Percentage\n",
      "notes                         70           86.419753\n",
      "base                          50           61.728395\n",
      "description                   49           60.493827\n",
      "uvt_base                      31           38.271605\n",
      "retention_concept             31           38.271605\n",
      "account_id                    31           38.271605\n",
      "created_at                    13           16.049383\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'retentions_applied' ---\n",
      "No se encontraron valores faltantes en la tabla 'retentions_applied'.\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'retentions_certificates' ---\n",
      "No se encontraron valores faltantes en la tabla 'retentions_certificates'.\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'taxes' ---\n",
      "Valores faltantes por columna:\n",
      "                           Missing Count  Missing Percentage\n",
      "notes                                 17           89.473684\n",
      "tax_account_deductible_id              5           26.315789\n",
      "created_at                             5           26.315789\n",
      "tax_account_generated_id               1            5.263158\n",
      "updated_at                             1            5.263158\n",
      "\n",
      "--- Analizando datos faltantes en la tabla: 'payments' ---\n",
      "Valores faltantes por columna:\n",
      "                    Missing Count  Missing Percentage\n",
      "deleted_at                    612           99.674267\n",
      "comments                      610           99.348534\n",
      "notes                         446           72.638436\n",
      "taxes                         290           47.231270\n",
      "retentions                    247           40.228013\n",
      "retentions_details            247           40.228013\n",
      "\n",
      "Proceso de revisión de datos faltantes completado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Asegúrate de que get_engine() está definida en db_connection.py\n",
    "from db_connection import get_engine\n",
    "\n",
    "# Lista de todas las tablas que hemos analizado\n",
    "tables_to_check = [\n",
    "    'accounting_account_balances',\n",
    "    'accounting_accounts',\n",
    "    'accounting_movements',\n",
    "    'accounting_voucher_items',\n",
    "    'accounting_voucher_types',\n",
    "    'accounting_vouchers',\n",
    "    'retention_concepts',\n",
    "    'retentions',\n",
    "    'retentions_applied',\n",
    "    'retentions_certificates',\n",
    "    'taxes',\n",
    "    'payments'\n",
    "]\n",
    "\n",
    "engine = None # Inicializar engine fuera del try para que sea accesible en finally\n",
    "\n",
    "try:\n",
    "    print(\"Conectando a la base de datos para revisar datos faltantes...\")\n",
    "    engine = get_engine()\n",
    "    print(\"Conexión a la base de datos establecida.\")\n",
    "\n",
    "    for table_name in tables_to_check:\n",
    "        print(f\"\\n--- Analizando datos faltantes en la tabla: '{table_name}' ---\")\n",
    "        try:\n",
    "            df = pd.read_sql(f'SELECT * FROM {table_name}', engine)\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"La tabla '{table_name}' está vacía. No hay datos que analizar.\")\n",
    "                continue\n",
    "\n",
    "            # Calcular la cantidad de valores nulos por columna\n",
    "            missing_values_count = df.isnull().sum()\n",
    "\n",
    "            # Calcular el porcentaje de valores nulos por columna\n",
    "            missing_values_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "            # Crear un DataFrame con el recuento y el porcentaje de nulos\n",
    "            missing_data_df = pd.DataFrame({\n",
    "                'Missing Count': missing_values_count,\n",
    "                'Missing Percentage': missing_values_percentage\n",
    "            })\n",
    "\n",
    "            # Filtrar solo las columnas que tienen valores faltantes\n",
    "            missing_data_df = missing_data_df[missing_data_df['Missing Count'] > 0].sort_values(by='Missing Percentage', ascending=False)\n",
    "\n",
    "            if missing_data_df.empty:\n",
    "                print(f\"No se encontraron valores faltantes en la tabla '{table_name}'.\")\n",
    "            else:\n",
    "                print(\"Valores faltantes por columna:\")\n",
    "                print(missing_data_df)\n",
    "\n",
    "            # Opcional: Visualización simple para tablas más pequeñas\n",
    "            # import matplotlib.pyplot as plt\n",
    "            # import seaborn as sns\n",
    "            # if not missing_data_df.empty:\n",
    "            #     plt.figure(figsize=(10, 6))\n",
    "            #     sns.barplot(x=missing_data_df.index, y='Missing Percentage', data=missing_data_df)\n",
    "            #     plt.title(f'Porcentaje de Valores Faltantes en {table_name}')\n",
    "            #     plt.ylabel('Porcentaje Faltante (%)')\n",
    "            #     plt.xticks(rotation=45, ha='right')\n",
    "            #     plt.tight_layout()\n",
    "            #     plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar o analizar la tabla '{table_name}': {e}\")\n",
    "            print(f\"Asegúrate de que la tabla '{table_name}' existe y es accesible.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error general de conexión a la base de datos: {e}\")\n",
    "finally:\n",
    "    if engine:\n",
    "        # Asegúrate de cerrar la conexión si es un motor que lo requiere explícitamente\n",
    "        # Para SQLAlchemy con un pool, esto no siempre es necesario o deseable.\n",
    "        # Pero es buena práctica si la conexión directa lo requiere.\n",
    "        # En general, el `engine` de SQLAlchemy maneja el pool de conexiones.\n",
    "        pass # La gestión de conexiones con `engine` de SQLAlchemy es automática.\n",
    "    print(\"\\nProceso de revisión de datos faltantes completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e4903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
